---
title: "`matos` for the power user"
date: 2023-22-02
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{`matos` for the power user}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(matos)
```

If you're a data manager for a lab that partakes in fish telemetry, you are likely balancing a number of projects at any one time. It can be pretty hard to keep track of what's new when an OTN data push occurs.

For example, I have 12 projects for which I am responsible.

```{r}
projects <- list_my_projects()

head(projects)
```

## Parallel

I like to use the [`future` family of packages](https://www.futureverse.org/packages-overview.html) to run things in parallel specifically, [`future.apply`](https://future.apply.futureverse.org/). When you get quite a few projects, this speeds up pulling your files from MATOS quite a bit.

## Listing

```{r message=FALSE}
library(future.apply)
plan(multisession)

# List files in all of my projects
extraction_files <- future_lapply(projects$number, 
                                  function(x){
                                    list_extract_files(x)
                                    }
                                  )

# Bind together into one data frame
extraction_files <- do.call(rbind, extraction_files)

head(extraction_files)
```

That's `r nrow(extraction_files)` files of which I need to keep track! It really adds up.

## Downloading

If we want to download all of those files, we can do something similar. We just need to change the function we're running in parallel to `get_extract_file` and provide it the URLs from the list we made via `list_extract_files`. I'll download the first three files for demonstration purposes.

```{r}
future_lapply(extraction_files$url[1:3], 
              function(x){
                get_extract_file(url = x)
              }
)
```

## Summarizing

We can do the same by looping through receiver and transmitter push summaries. For me, this will create 24 reports! Still a lot, but quite a bit easier to digest than millions of detections spread over `r nrow(extraction_files)` files.

```{r eval=FALSE}
future_lapply(projects$number[1:2], 
              function(x){
                make_receiver_push_summary(x)
              }
)

future_lapply(projects$number[1:2], 
              function(x){
                make_receiver_tag_summary(x)
              }
)
```

